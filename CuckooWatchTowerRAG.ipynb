{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO38kDHctYpoFXdmcenwSwJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WizardML7/Cuckoo-Watchtower/blob/main/CuckooWatchTowerRAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PLX_SeAacZrn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f764d1ae-d899-4ece-f044-efb0fd6e742e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.17-py3-none-any.whl (867 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m867.6/867.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai\n",
            "  Downloading openai-1.25.1-py3-none-any.whl (312 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.9/312.9 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting weaviate-client\n",
            "  Downloading weaviate_client-4.5.7-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.5-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.36 (from langchain)\n",
            "  Downloading langchain_community-0.0.36-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.48 (from langchain)\n",
            "  Downloading langchain_core-0.1.50-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.8/302.8 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.54-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.7/116.7 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Collecting validators==0.28.1 (from weaviate-client)\n",
            "  Downloading validators-0.28.1-py3-none-any.whl (39 kB)\n",
            "Collecting authlib<2.0.0,>=1.2.1 (from weaviate-client)\n",
            "  Downloading Authlib-1.3.0-py2.py3-none-any.whl (223 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.7/223.7 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: grpcio<2.0.0,>=1.57.0 in /usr/local/lib/python3.10/dist-packages (from weaviate-client) (1.63.0)\n",
            "Collecting grpcio-tools<2.0.0,>=1.57.0 (from weaviate-client)\n",
            "  Downloading grpcio_tools-1.63.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting grpcio-health-checking<2.0.0,>=1.57.0 (from weaviate-client)\n",
            "  Downloading grpcio_health_checking-1.63.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.10/dist-packages (from authlib<2.0.0,>=1.2.1->weaviate-client) (42.0.5)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting protobuf<6.0dev,>=5.26.1 (from grpcio-health-checking<2.0.0,>=1.57.0->weaviate-client)\n",
            "  Downloading protobuf-5.26.1-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.8/302.8 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from grpcio-tools<2.0.0,>=1.57.0->weaviate-client) (67.7.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.48->langchain)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography->authlib<2.0.0,>=1.2.1->weaviate-client) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography->authlib<2.0.0,>=1.2.1->weaviate-client) (2.22)\n",
            "Installing collected packages: validators, protobuf, packaging, orjson, mypy-extensions, jsonpointer, h11, typing-inspect, marshmallow, jsonpatch, httpcore, grpcio-tools, grpcio-health-checking, langsmith, httpx, dataclasses-json, authlib, weaviate-client, openai, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-ai-generativelanguage 0.6.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n",
            "google-api-core 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n",
            "google-cloud-aiplatform 1.48.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.24.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n",
            "google-cloud-datastore 2.15.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n",
            "google-cloud-firestore 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n",
            "google-cloud-functions 1.13.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n",
            "google-cloud-iam 2.15.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n",
            "google-cloud-language 2.13.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n",
            "google-cloud-resource-manager 1.12.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n",
            "google-cloud-translate 3.11.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n",
            "googleapis-common-protos 1.63.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n",
            "grpc-google-iam-v1 0.13.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n",
            "proto-plus 1.23.0 requires protobuf<5.0.0dev,>=3.19.0, but you have protobuf 5.26.1 which is incompatible.\n",
            "tensorflow 2.15.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.26.1 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 5.26.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed authlib-1.3.0 dataclasses-json-0.6.5 grpcio-health-checking-1.63.0 grpcio-tools-1.63.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.17 langchain-community-0.0.36 langchain-core-0.1.50 langchain-text-splitters-0.0.1 langsmith-0.1.54 marshmallow-3.21.2 mypy-extensions-1.0.0 openai-1.25.1 orjson-3.10.3 packaging-23.2 protobuf-5.26.1 typing-inspect-0.9.0 validators-0.28.1 weaviate-client-4.5.7\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.6.0\n",
            "Collecting pymongo\n",
            "  Downloading pymongo-4.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (669 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.0/670.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dnspython, pymongo\n",
            "Successfully installed dnspython-2.6.1 pymongo-4.7.1\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain openai weaviate-client\n",
        "!pip install tiktoken\n",
        "!pip install pymongo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\""
      ],
      "metadata": {
        "id": "iUkJPYO3c2WU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def load_report(report_path):\n",
        "    \"\"\"Load the JSON report.\"\"\"\n",
        "    with open(report_path, 'r') as file:\n",
        "        return json.load(file)\n",
        "\n",
        "def get_process_info(cuckoo_report):\n",
        "    \"\"\"Extract process information.\"\"\"\n",
        "    processes_info = cuckoo_report[\"behavior\"][\"processes\"]\n",
        "    malware_pid = processes_info[0][\"pid\"]\n",
        "    child_pids = [proc[\"pid\"] for proc in processes_info if proc[\"ppid\"] == malware_pid]\n",
        "    return malware_pid, child_pids\n",
        "\n",
        "def get_virustotal_names(cuckoo_report):\n",
        "    \"\"\"Extract malware names from VirusTotal scanners.\"\"\"\n",
        "    vt_results = cuckoo_report.get(\"virustotal\", {}).get(\"scans\", {})\n",
        "    malware_names = [details[\"result\"] for scanner, details in vt_results.items() if details[\"result\"] is not None][:30]\n",
        "    return malware_names\n",
        "\n",
        "def get_top_entries(data_dict, top_n=30):\n",
        "    \"\"\"Return top_n entries for each key in a dictionary.\"\"\"\n",
        "    return {key: value[:top_n] for key, value in data_dict.items()}\n",
        "\n",
        "def get_dlls_loaded_by_process(processes_info):\n",
        "    \"\"\"Extract the DLLs loaded by each process.\"\"\"\n",
        "    return get_top_entries({proc[\"pid\"]: proc.get(\"loaded_dlls\", []) for proc in processes_info})\n",
        "\n",
        "def get_api_calls_by_process(processes_info):\n",
        "    \"\"\"Extract the API calls made by each process.\"\"\"\n",
        "    return get_top_entries({proc[\"pid\"]: [call[\"api\"] for call in proc.get(\"calls\", [])] for proc in processes_info})\n",
        "\n",
        "def get_registry_operations(cuckoo_report):\n",
        "    \"\"\"Extract registry operations.\"\"\"\n",
        "    return cuckoo_report[\"behavior\"][\"summary\"].get(\"regkey_written\", [])[:30]\n",
        "\n",
        "def get_filesystem_operations(cuckoo_report):\n",
        "    \"\"\"Extract filesystem operations.\"\"\"\n",
        "    return cuckoo_report[\"behavior\"][\"summary\"].get(\"file_written\", [])[:30]\n",
        "\n",
        "def write_report_to_file(filename, data):\n",
        "    \"\"\"Write the extracted data to a text file.\"\"\"\n",
        "    with open(filename, 'w') as f:\n",
        "        for key, value in data.items():\n",
        "            f.write(f\"{key}:\\n{value}\\n\\n\")"
      ],
      "metadata": {
        "id": "Ic1jYmf1gmem"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Where I want to create clean files\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "report_path = \"/content/drive/MyDrive/CSEC MalwareForensics/FinalData/15/reports/report.json\"\n",
        "cuckoo_report = load_report(report_path)\n",
        "\n",
        "# Extract information\n",
        "malware_pid, child_pids = get_process_info(cuckoo_report)\n",
        "malware_names = get_virustotal_names(cuckoo_report)\n",
        "dlls_by_process = get_dlls_loaded_by_process(cuckoo_report[\"behavior\"][\"processes\"])\n",
        "api_calls_by_process = get_api_calls_by_process(cuckoo_report[\"behavior\"][\"processes\"])\n",
        "registry_operations = get_registry_operations(cuckoo_report)\n",
        "filesystem_operations = get_filesystem_operations(cuckoo_report)\n",
        "\n",
        "# Data dictionary to be written to the file\n",
        "data_to_write = {\n",
        "    \"PID and Child PIDs\": f\"PID: {malware_pid}, Child PIDs: {child_pids}\",\n",
        "    \"Names from VirusTotal\": malware_names,\n",
        "    \"Top DLLs Loaded by Process\": dlls_by_process,\n",
        "    \"Top API Calls by Process\": api_calls_by_process,\n",
        "    \"Top Registry Operations\": registry_operations,\n",
        "    \"Top Filesystem Operations\": filesystem_operations\n",
        "}\n",
        "\n",
        "# Write data to file\n",
        "output_filename = 'report_summary.txt'\n",
        "write_report_to_file(output_filename, data_to_write)\n",
        "\n",
        "\n",
        "def extract_signatures_to_file(file_path, output_file):\n",
        "    # Load JSON data from a file\n",
        "    with open(file_path, 'r') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    # Extract the signatures section\n",
        "    signatures = data.get('signatures', [])\n",
        "\n",
        "    # Write signatures to a text file\n",
        "    with open(output_file, 'w') as outfile:\n",
        "        for signature in signatures:\n",
        "            outfile.write(f\"Signature Name: {signature.get('name')}\\n\")\n",
        "            outfile.write(f\"Description: {signature.get('description')}\\n\")\n",
        "            outfile.write(f\"Severity: {signature.get('severity')}\\n\")\n",
        "            outfile.write(f\"Mark Count: {signature.get('markcount')}\\n\")\n",
        "            outfile.write(f\"Family: {', '.join(signature.get('families', []))}\\n\")\n",
        "            outfile.write(f\"References: {', '.join(signature.get('references', []))}\\n\")\n",
        "            outfile.write(\"-\" * 40 + \"\\n\")\n",
        "\n",
        "\n",
        "extract_signatures_to_file('/content/drive/MyDrive/CSEC MalwareForensics/FinalData/15/reports/report.json', 'signatures_output.txt')\n",
        "\n",
        "def extract_network_to_file(file_path, output_file):\n",
        "    # Load JSON data from a file\n",
        "    with open(file_path, 'r') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    # Extract the network section\n",
        "    network = data.get('network', {})\n",
        "\n",
        "    # Write network data to a text file\n",
        "    with open(output_file, 'w') as outfile:\n",
        "        if network:\n",
        "            # General network information\n",
        "            outfile.write(f\"TLS Info: {network.get('tls', 'Not available')}\\n\")\n",
        "            outfile.write(f\"DNS Servers: {', '.join(network.get('dns_servers', []))}\\n\")\n",
        "            outfile.write(f\"HTTP Traffic: {network.get('http', 'Not available')}\\n\")\n",
        "            outfile.write(f\"SMTP Traffic: {network.get('smtp', 'Not available')}\\n\")\n",
        "            outfile.write(f\"ICMP Traffic: {network.get('icmp', 'Not available')}\\n\")\n",
        "            outfile.write(f\"Domains: {network.get('domains', 'Not available')}\\n\")\n",
        "            outfile.write(f\"Dead Hosts: {network.get('dead_hosts', 'Not available')}\\n\")\n",
        "            outfile.write(\"-\" * 40 + \"\\n\")\n",
        "\n",
        "            # Detailed UDP Traffic\n",
        "            if 'udp' in network:\n",
        "                outfile.write(\"UDP Traffic Details:\\n\")\n",
        "                for udp in network['udp']:\n",
        "                    outfile.write(f\"Source: {udp.get('src', 'Unknown')}, \")\n",
        "                    outfile.write(f\"Destination: {udp.get('dst', 'Unknown')}, \")\n",
        "                    outfile.write(f\"Source Port: {udp.get('sport', 'Unknown')}, \")\n",
        "                    outfile.write(f\"Destination Port: {udp.get('dport', 'Unknown')}\\n\")\n",
        "                outfile.write(\"-\" * 40 + \"\\n\")\n",
        "\n",
        "            # DNS activity\n",
        "            dns_activities = network.get('dns', [])\n",
        "            outfile.write(\"DNS Activities:\\n\")\n",
        "            for dns in dns_activities:\n",
        "                outfile.write(f\"Request: {dns.get('request', 'Unknown')}, Answers: {', '.join([ans.get('data', 'No data') for ans in dns.get('answers', [])])}\\n\")\n",
        "            outfile.write(\"-\" * 40 + \"\\n\")\n",
        "\n",
        "            # HTTP traffic\n",
        "            if 'http' in network:\n",
        "                outfile.write(\"HTTP Traffic Details:\\n\")\n",
        "                for http in network['http']:\n",
        "                    outfile.write(f\"Method: {http.get('method', 'Unknown')}, URL: {http.get('uri', 'Unknown')}, Status Code: {http.get('status_code', 'Unknown')}\\n\")\n",
        "                outfile.write(\"-\" * 40 + \"\\n\")\n",
        "\n",
        "\n",
        "extract_network_to_file('/content/drive/MyDrive/CSEC MalwareForensics/FinalData/15/reports/report.json', 'network_output.txt')\n",
        "\n",
        "\n",
        "def extract_static_to_file(file_path, output_file):\n",
        "    # Load JSON data from a file\n",
        "    with open(file_path, 'r') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    # Extract the static section\n",
        "    static = data.get('static', {})\n",
        "\n",
        "\n",
        "    with open(output_file, 'w') as outfile:\n",
        "        if static:\n",
        "            # PE Timestamp and other information\n",
        "            outfile.write(f\"PDB Path: {static.get('pdb_path', 'Not available')}\\n\")\n",
        "            outfile.write(f\"PE Timestamp: {static.get('pe_timestamp', 'Not available')}\\n\")\n",
        "            outfile.write(f\"Imported DLL Count: {static.get('imported_dll_count', 'Not available')}\\n\")\n",
        "            outfile.write(f\"PE ImpHash: {static.get('pe_imphash', 'Not available')}\\n\")\n",
        "\n",
        "            # PE Imports\n",
        "            pe_imports = static.get('pe_imports', [])\n",
        "            outfile.write(\"PE Imports:\\n\")\n",
        "            for item in pe_imports:\n",
        "                outfile.write(f\"DLL: {item.get('dll', 'Unknown')}\\n\")\n",
        "                for imp in item.get('imports', []):\n",
        "                    outfile.write(f\"  Import Name: {imp.get('name', 'Unknown')}, Address: {imp.get('address', 'Unknown')}\\n\")\n",
        "            outfile.write(\"-\" * 40 + \"\\n\")\n",
        "\n",
        "            # Static Signatures\n",
        "            signatures = static.get('signature', [])\n",
        "            outfile.write(\"Signatures:\\n\")\n",
        "            for sig in signatures:\n",
        "                outfile.write(f\"  Organization: {sig.get('organization', 'Unknown')}, \")\n",
        "                outfile.write(f\"Common Name: {sig.get('common_name', 'Unknown')}\\n\")\n",
        "            outfile.write(\"-\" * 40 + \"\\n\")\n",
        "\n",
        "            # PE Sections\n",
        "            pe_sections = static.get('pe_sections', [])\n",
        "            outfile.write(\"PE Sections:\\n\")\n",
        "            for section in pe_sections:\n",
        "                outfile.write(f\"  Section Name: {section.get('name', 'Unknown')}, \")\n",
        "                outfile.write(f\"Size of Data: {section.get('size_of_data', 'Unknown')}, \")\n",
        "                outfile.write(f\"Virtual Address: {section.get('virtual_address', 'Unknown')}\\n\")\n",
        "            outfile.write(\"-\" * 40 + \"\\n\")\n",
        "\n",
        "extract_static_to_file('/content/drive/MyDrive/CSEC MalwareForensics/FinalData/15/reports/report.json', 'static_output.txt')\n"
      ],
      "metadata": {
        "id": "rs4kMRJohhSW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d340583-de1b-4e6d-c94b-77360a5cd89b"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import TextLoader\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "document_files = glob.glob('/content/*.txt')\n",
        "documents = []\n",
        "for file_path in document_files:\n",
        "    loader = TextLoader(file_path)\n",
        "    documents.extend(loader.load())"
      ],
      "metadata": {
        "id": "kGhSwhDufimU"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "#all_chunks = [chunk for document in documents for chunk in text_splitter.split_document(document)]\n",
        "chunks = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "mWWn31XEhozx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6080bc2-a09d-48c4-8b93-8a95d0b64f20"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_text_splitters.base:Created a chunk of size 3686, which is longer than the specified 500\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 3665, which is longer than the specified 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Weaviate\n",
        "import weaviate\n",
        "from weaviate.embedded import EmbeddedOptions\n",
        "\n",
        "\n",
        "\n",
        "client = weaviate.Client(\n",
        "  embedded_options = EmbeddedOptions()\n",
        ")\n",
        "\n",
        "vectorstore = Weaviate.from_documents(\n",
        "    client = client,\n",
        "    documents = chunks,\n",
        "    embedding = OpenAIEmbeddings(),\n",
        "    by_text = False\n",
        ")"
      ],
      "metadata": {
        "id": "l4-lwJlRiGI6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e11c30e5-298e-492e-9bf6-6c08c2c43d86"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embedded weaviate is already listening on port 8079\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "ip18t4PSmhSZ"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "template = \"\"\"You are an assistant for malware event analysis. If the user asks questions that are completely unrelated to malware event analysis refuse to answer their question and state that your purpose is to answer questions related to malware and analyze the malware event data.\n",
        "If you don't know the answer, just say that you don't know.\n",
        "Question: {question}\n",
        "Context: {context}\n",
        "Answer:\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "print(prompt)"
      ],
      "metadata": {
        "id": "NQz1GpFRml2l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5b1fd71-79cb-4760-ad84-858677b5807c"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_variables=['context', 'question'] messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant for malware event analysis. If the user asks questions that are completely unrelated to malware event analysis refuse to answer their question and state that your purpose is to answer questions related to malware and analyze the malware event data. \\nIf you don't know the answer, just say that you don't know.\\nQuestion: {question}\\nContext: {context}\\nAnswer:\\n\"))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-4-turbo-preview\", temperature=0)\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": retriever,  \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "\n",
        "query = input(\"Please enter your question: \")\n",
        "\n",
        "# Invoke the chain with the user query and print the response\n",
        "response = rag_chain.invoke(query)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "-VTm91hOmpPq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35fffbe3-1060-4022-f12d-30ba9b452c7c"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter your question: Provide a comprehensive report on the program analyzed. \n",
            "Based on the provided documents, the analyzed program exhibits several characteristics and behaviors indicative of potentially malicious activity. Here's a comprehensive report summarizing the findings:\n",
            "\n",
            "**Process Information:**\n",
            "- **PID:** 516 with no child processes identified.\n",
            "\n",
            "**Signatures Detected:**\n",
            "1. **Console Output:** Command line console output was observed, indicating potential command-line interface manipulation or execution.\n",
            "2. **Authenticode:** The executable is signed, suggesting an attempt to appear legitimate.\n",
            "3. **Anti-VM Techniques:** The program checks the amount of memory available, possibly to detect virtual machines.\n",
            "4. **Unknown PE Resource Name:** Contains an unknown PE resource name, which could indicate packing or obfuscation techniques.\n",
            "5. **Allocates RWX Memory:** Allocates read-write-execute memory, typically for unpacking or executing in-memory payloads.\n",
            "6. **Anti-Sandbox Techniques:** Attempts to delay analysis through sleep functions.\n",
            "7. **Browser Hijacking:** Attempts to modify Internet Explorer's start page.\n",
            "8. **Suspicious Process Creation:** Creates processes that may be considered suspicious.\n",
            "9. **Executable Dropping:** Drops executables to the user's AppData folder, a common tactic for persistence and evasion.\n",
            "10. **Stealth Techniques:** Creates a hidden window, possibly to evade detection by the user or security software.\n",
            "11. **Anti-VM Network Adapter Checks:** Checks network adapter addresses, likely to detect virtual environments.\n",
            "12. **Use of Windows Utilities:** Utilizes Windows utilities for potentially malicious purposes.\n",
            "13. **No DNS Lookup Communication:** Communicates with hosts without performing DNS queries, indicative of direct IP communication to avoid detection.\n",
            "14. **Info Stealer Keylogger:** Implements a keylogger functionality, monitoring keyboard input.\n",
            "15. **Multiple User Agents:** Exhibits network activity with more than one unique user agent, suggesting attempts to mimic different systems or browsers.\n",
            "16. **Process Injection:** Resumes a suspended thread in a remote process, indicative of process injection techniques.\n",
            "17. **ICMP Traffic:** Generates ICMP traffic, which could be used for network reconnaissance or signaling.\n",
            "18. **Dead Host Communication:** Attempts to connect to IP addresses that do not respond, possibly indicating command and control communication attempts with fallback mechanisms.\n",
            "\n",
            "**PE Analysis:**\n",
            "- **Timestamp:** 2017-11-22 00:45:43\n",
            "- **Imported DLL Count:** 10\n",
            "- **PE ImpHash:** 460c803d3984135d17296da91c93d9fd\n",
            "- **Significant DLLs Loaded:** KERNEL32.dll, USER32.dll, GDI32.dll, ADVAPI32.dll, SHELL32.dll, ole32.dll, OLEAUT32.dll, SHLWAPI.dll, WININET.dll\n",
            "- **Notable Imports:** Functions related to process and thread management, network communication, file manipulation, and registry access, which are common in malware for execution, persistence, and data exfiltration.\n",
            "\n",
            "**Top API Calls:**\n",
            "- The program makes numerous calls to APIs such as `GetSystemTimeAsFileTime`, `LdrLoadDll`, `RegOpenKeyExW`, and `SetUnhandledExceptionFilter`, among others. These calls are consistent with behaviors such as dynamic loading of libraries, registry access for persistence or configuration, and exception handling to maintain stability or evade analysis.\n",
            "\n",
            "**Conclusion:**\n",
            "The analyzed program demonstrates a range of behaviors that are strongly indicative of malicious intent, including evasion, persistence, stealth, and data exfiltration techniques. The presence of anti-VM and anti-sandbox characteristics, alongside the use of authenticode signing and suspicious network behavior, suggests a sophisticated threat actor aiming to avoid detection and analysis. Further investigation and appropriate defensive measures are recommended.\n"
          ]
        }
      ]
    }
  ]
}